{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Skin Issues\n",
    "\n",
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.736566Z",
     "start_time": "2021-07-23T07:45:50.218598Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import randint\n",
    "from skimage.transform import resize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import sys  \n",
    "sys.path.insert(0, './code')\n",
    "from util import AddGaussianNoise\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from util import AddGaussianNoise\n",
    "from sklearn.utils import shuffle\n",
    "from center_loss import CenterLoss\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.753084Z",
     "start_time": "2021-07-23T07:45:51.747256Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Source code credit for this function: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14, name = \"noName\"):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pandas.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.769734Z",
     "start_time": "2021-07-23T07:45:51.754690Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def testAccuracy(model):\n",
    "    PCAVector = []\n",
    "    truth = []\n",
    "    correctPred = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for i in range(len(datasetTest)):\n",
    "        output = model(datasetTest[i][0].unsqueeze(0).to(device))\n",
    "        output = np.array(output.detach().to('cpu'))\n",
    "        if datasetTest[i][1] == np.argmax(output[0]):\n",
    "            correctPred += 1\n",
    "        PCAVector.append(np.array(activation['avgpool'].to('cpu')).reshape(-1))\n",
    "        truth.append(datasetTest[i][1])\n",
    "        print(\"{:.2f} % ({:d} su {:d}) acc = {:.2f}\".format(100*i/len(datasetTest), i, len(datasetTest), 100 * correctPred / (i + 1)), end=\"\\r\")\n",
    "    print(\"Accuracy of prediction (\"+ model.name+ \") \"+str(correctPred/len(datasetTest)))\n",
    "    \n",
    "    tsne = TSNE(n_components=2)\n",
    "    PCAtoplot = tsne.fit_transform(np.array(PCAVector))\n",
    "    PCAtoplot = np.append(PCAtoplot, np.array(truth).reshape(-1, 1), axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    firstLabel = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    \n",
    "    for x, y, color in PCAtoplot:\n",
    "        color = int(color)\n",
    "        if color == 0:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'bo', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'bo')\n",
    "        if color == 1:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'go', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'go')\n",
    "        if color == 2:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'ro', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'ro')\n",
    "        if color == 3:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'yo', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'yo')\n",
    "        if color == 4:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'kd', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'kd')\n",
    "        if color == 5:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'ch', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'ch')\n",
    "        if color == 6:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'm*', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'm*')\n",
    "        if color == 7:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'bs', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'bs')\n",
    "            \n",
    "    plt.ylabel('PC1')\n",
    "    plt.xlabel('PC2')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.776743Z",
     "start_time": "2021-07-23T07:45:51.770736Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def verifyAccuracy(model, dataloader, test = True):\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        predictions = []\n",
    "        truth = []\n",
    "        \n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(8)]\n",
    "        n_class_samples = [0 for i in range(8)]\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(images.shape[0]):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                predictions.append(np.array(pred.to('cpu')))\n",
    "                truth.append(np.array(label.to('cpu')))\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network {model.name}: {acc} %')\n",
    "\n",
    "        truth = np.array(truth)\n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        balAcc = balanced_accuracy_score(truth, predictions)\n",
    "        print(f'Balanced accuracy of the network {model.name}: {balAcc} %')\n",
    "        if test:\n",
    "            model.testAcc = balAcc\n",
    "        elif model.maxValAcc < balAcc:\n",
    "            model.maxValAcc = balAcc\n",
    "        \n",
    "        cm = confusion_matrix(truth,predictions)\n",
    "        print_confusion_matrix(cm,labelName[:8],name = model.name)\n",
    "        print(classification_report(truth, predictions, target_names=labelName[:8]))\n",
    "\n",
    "        for i in range(8):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {labelName[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.783446Z",
     "start_time": "2021-07-23T07:45:51.777583Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def reduceDataframe(dataframe, perc):\n",
    "    dfTrainReduced = pandas.DataFrame(columns=labelName)\n",
    "    for label in labelName:\n",
    "        dfTrainReduced = pandas.concat([dataframe[dataframe[label]==1.].iloc[:round(perc*len(dataframe[dataframe[label]==1.]))], dfTrainReduced], axis = 0)\n",
    "\n",
    "    dfTrainReduced.reset_index(drop=True, inplace = True)\n",
    "    return dfTrainReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.795262Z",
     "start_time": "2021-07-23T07:45:51.792121Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 600\n",
    "gpus = [0, 3]\n",
    "BATCH_SIZE = 80 * len(gpus)\n",
    "batches = round(640 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.803075Z",
     "start_time": "2021-07-23T07:45:51.796650Z"
    }
   },
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.908932Z",
     "start_time": "2021-07-23T07:45:51.804506Z"
    }
   },
   "outputs": [],
   "source": [
    "skinDataset = []\n",
    "labelName = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]\n",
    "\n",
    "i = 0\n",
    "#Reading the labels\n",
    "df = pandas.read_csv(\"label.csv\")\n",
    "df = shuffle(df, random_state = 1234)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "dfTrain = df[df[\"MEL\"]==1.].iloc[:round(0.9*len(df[df[\"MEL\"]==1.]))]\n",
    "\n",
    "for label in [\"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]:\n",
    "    dfTrain = pandas.concat([dfTrain, df[df[label]==1.].iloc[:round(0.9*len(df[df[label]==1.]))]])\n",
    "    \n",
    "dfTrain = dfTrain.reset_index(drop=True)\n",
    "\n",
    "dfTest = pandas.concat([df,dfTrain]).drop_duplicates(keep=False)\n",
    "dfVal = dfTrain.copy()\n",
    "dfTrain = dfVal[dfVal[\"MEL\"]==1.].iloc[:round(0.9*len(dfVal[dfVal[\"MEL\"]==1.]))]\n",
    "\n",
    "for label in [\"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]:\n",
    "    dfTrain = pandas.concat([dfTrain, dfVal[dfVal[label]==1.].iloc[:round(0.9*len(dfVal[dfVal[label]==1.]))]])\n",
    "    \n",
    "\n",
    "dfVal = pandas.concat([dfVal,dfTrain]).drop_duplicates(keep=False)\n",
    "dfTest = dfTest.reset_index(drop=True)\n",
    "dfVal = dfVal.reset_index(drop=True)\n",
    "dfTrain = dfTrain.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.915276Z",
     "start_time": "2021-07-23T07:45:51.910505Z"
    }
   },
   "outputs": [],
   "source": [
    "#Per verificare che il dataset sia ben bilanciato\n",
    "def isBalanced(df):\n",
    "    MELCount = len(df[df['MEL']==1.])\n",
    "    NVCount = len(df[df['NV']==1.])\n",
    "    BCCCount = len(df[df['BCC']==1.])\n",
    "    AKCount = len(df[df['AK']==1.])\n",
    "    BKLCount = len(df[df['BKL']==1.])\n",
    "    DFCount = len(df[df['DF']==1.])\n",
    "    VASCCount = len(df[df['VASC']==1.])\n",
    "    SCCCount = len(df[df['SCC']==1.])\n",
    "    UNKCount = len(df[df['UNK']==1.])\n",
    "\n",
    "    print(\"Casi di MEL: \" + str(MELCount))\n",
    "    print(\"Casi di NV: \" + str(NVCount))\n",
    "    print(\"Casi di BCC: \" + str(BCCCount))\n",
    "    print(\"Casi di AK: \" + str(AKCount))\n",
    "    print(\"Casi di BKL: \" + str(BKLCount))\n",
    "    print(\"Casi di DF: \" + str(DFCount))\n",
    "    print(\"Casi di VASC: \" + str(VASCCount))\n",
    "    print(\"Casi di SCC: \" + str(SCCCount))\n",
    "    print(\"Casi di UNK: \" + str(UNKCount))\n",
    "\n",
    "print(\"Le dimensioni del dataset di training sono : \"+str(dfTrain.shape[0])+\" , mentre le dimensioni del dataset di test sono \"+str(dfTest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.922239Z",
     "start_time": "2021-07-23T07:45:51.916175Z"
    }
   },
   "outputs": [],
   "source": [
    "def BalanceVector(df, lowLimit = 0):\n",
    "    values = []\n",
    "    \n",
    "    for name in labelName[:-1]:\n",
    "        values.append(len(df[df[name]==1.]))\n",
    "        \n",
    "    values = np.array(values)\n",
    "    \n",
    "    values = 1 / values\n",
    "    \n",
    "    values = values / values.sum() \n",
    "    \n",
    "    for i in range(len(values)):\n",
    "        if values[i] < lowLimit:\n",
    "            values[i] = lowLimit\n",
    "            \n",
    "    values = values / values.sum() \n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.928975Z",
     "start_time": "2021-07-23T07:45:51.923117Z"
    }
   },
   "outputs": [],
   "source": [
    "def BalanceVectorCB(df, beta = 0):\n",
    "    values = []\n",
    "    \n",
    "    for name in labelName[:-1]:\n",
    "        values.append(float(len(df[df[name]==1.])))\n",
    "        \n",
    "    values = np.array(values)\n",
    "    \n",
    "    for i in range(len(values)):\n",
    "        values[i] = (1 - beta)/(1 - pow(beta, values[i]))\n",
    "            \n",
    "    values = values / values.sum() \n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.947368Z",
     "start_time": "2021-07-23T07:45:51.929994Z"
    }
   },
   "outputs": [],
   "source": [
    "isBalanced(dfTrain)\n",
    "w = BalanceVectorCB(dfTrain, beta = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.951045Z",
     "start_time": "2021-07-23T07:45:51.948512Z"
    }
   },
   "outputs": [],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.956762Z",
     "start_time": "2021-07-23T07:45:51.952080Z"
    }
   },
   "outputs": [],
   "source": [
    "pow(0.99, 194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.962267Z",
     "start_time": "2021-07-23T07:45:51.957763Z"
    },
    "code_folding": [
     0,
     7,
     13,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def showImage(image, isTensor = False):\n",
    "    if isTensor:\n",
    "        plt.imshow(image.permute(1, 2, 0), interpolation='nearest', aspect='equal')\n",
    "    else:\n",
    "        plt.imshow(image, interpolation='nearest', aspect='equal')\n",
    "    plt.show()\n",
    "    \n",
    "def showLabel(label, prediction = False):\n",
    "    if prediction:\n",
    "        print(\"(Output della rete) La malattia è: \" + labelName[label])\n",
    "    else:\n",
    "        print(\"La malattia è: \" + labelName[label])\n",
    "    \n",
    "def showExample(example, isTensor = False):\n",
    "    showLabel(example[1])\n",
    "    showImage(example[0], isTensor)\n",
    "    \n",
    "def showLatent(label):\n",
    "    print(label.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.967637Z",
     "start_time": "2021-07-23T07:45:51.963544Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "imageTransform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "#transforms.GaussianBlur(5, sigma=(0.1, 1.0))\n",
    "\n",
    "randomTransform = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.05, hue=0.05),\n",
    "        #AddGaussianNoise(0., .08),\n",
    "        #transforms.RandomApply(torch.nn.ModuleList([\n",
    "        #    transforms.GaussianBlur(7, sigma=(0.2, 2.0))\n",
    "        #]), p=0.8),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomAffine((-180, 180), fill=0, scale = (0.7, 1.7), shear=(-30, 30))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.974742Z",
     "start_time": "2021-07-23T07:45:51.969103Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TotalDataset(Dataset):\n",
    "    def __init__(self, label, imgSize = 224, aug = False):\n",
    "        self.label = label\n",
    "        self.lenght = self.label.shape[0]\n",
    "        self.aug = transforms.Resize((imgSize, imgSize))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        pathImage = 'ISIC_2019_Training_Input/' + self.label['image'][index] + '.jpg'\n",
    "        label = np.argmax(np.array(self.label.loc[index][1:], dtype = 'float32' )[:-1])\n",
    "        image = imageTransform(Image.open(pathImage))\n",
    "        image = self.aug(image)\n",
    "        return (image, torch.tensor(label))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:51.980304Z",
     "start_time": "2021-07-23T07:45:51.976208Z"
    }
   },
   "outputs": [],
   "source": [
    "datasetTrain = TotalDataset(dfTrain)\n",
    "datasetVal = TotalDataset(dfVal)\n",
    "datasetTest = TotalDataset(dfTest)\n",
    "\n",
    "dataloaderTrain = DataLoader(dataset=datasetTrain, batch_size=BATCH_SIZE , shuffle=True, num_workers=8 )\n",
    "dataloaderTest = DataLoader(dataset=datasetTest, batch_size=BATCH_SIZE , num_workers=8 )\n",
    "dataloaderVal = DataLoader(dataset=datasetVal, batch_size=BATCH_SIZE, num_workers=8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:52.267784Z",
     "start_time": "2021-07-23T07:45:51.981697Z"
    }
   },
   "outputs": [],
   "source": [
    "showImage(datasetTest[0][0], isTensor= True)\n",
    "showImage(randomTransform(datasetTest[0][0]), isTensor= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.503618Z",
     "start_time": "2021-07-23T07:45:52.268816Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    example = randint(0, len(datasetTrain))\n",
    "    showExample(datasetTrain[example], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models pythorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.509353Z",
     "start_time": "2021-07-23T07:45:53.506502Z"
    }
   },
   "outputs": [],
   "source": [
    "def makePrediction(image, Model, label = False, latent = False, o = True):\n",
    "    Model.to('cpu')\n",
    "    #Predict with the NN\n",
    "    output = Model(image.unsqueeze(0))\n",
    "    output = np.array(output.detach())\n",
    "    if o:\n",
    "        showLabel(np.argmax(output), prediction = True)\n",
    "    if latent:\n",
    "        showLatent(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.541481Z",
     "start_time": "2021-07-23T07:45:53.510772Z"
    }
   },
   "outputs": [],
   "source": [
    "from PLModel import PLModel\n",
    "from BYOL import BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.624564Z",
     "start_time": "2021-07-23T07:45:53.542531Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "Models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.710729Z",
     "start_time": "2021-07-23T07:45:53.625469Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB0', EfficientNet.from_pretrained('efficientnet-b0', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.808944Z",
     "start_time": "2021-07-23T07:45:53.712251Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB1', EfficientNet.from_pretrained('efficientnet-b1', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:53.912891Z",
     "start_time": "2021-07-23T07:45:53.810177Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB2', EfficientNet.from_pretrained('efficientnet-b2', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:54.048001Z",
     "start_time": "2021-07-23T07:45:53.914122Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB3', EfficientNet.from_pretrained('efficientnet-b3', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:54.454910Z",
     "start_time": "2021-07-23T07:45:54.049279Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB5', EfficientNet.from_pretrained('efficientnet-b5', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:54.863553Z",
     "start_time": "2021-07-23T07:45:54.456183Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB6', EfficientNet.from_pretrained('efficientnet-b6', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:55.488178Z",
     "start_time": "2021-07-23T07:45:54.865791Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB7', EfficientNet.from_pretrained('efficientnet-b7', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnext50_32x4d', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnext50', resnext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnext152', resnext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:55.490865Z",
     "start_time": "2021-07-23T07:45:55.489200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "classificationModel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:45:55.707169Z",
     "start_time": "2021-07-23T07:45:55.491729Z"
    }
   },
   "outputs": [],
   "source": [
    "optimName = 'MADGRAD'\n",
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T17:51:27.139511Z",
     "start_time": "2021-07-23T07:45:55.709166Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "w = BalanceVector(dfTrain)\n",
    "loss = nn.CrossEntropyLoss(weight = torch.tensor(w, dtype=torch.float))\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "resolutions = [224, 240, 260, 300, 456, 528, 600, 600, 600]\n",
    "\n",
    "for model, resolution,layer in zip(Models, resolutions, layers):\n",
    "    print(\"Train to downstream task network \" + model.name+\" at resolution \"+ str(resolution))\n",
    "    lr = 0.00025\n",
    "    \n",
    "    datasetTrain = TotalDataset(dfTrain, imgSize = resolution )\n",
    "    datasetVal = TotalDataset(dfVal, imgSize = resolution)\n",
    "    datasetTest = TotalDataset(dfTest, imgSize = resolution)\n",
    "    \n",
    "    BATCH_SIZE = 50\n",
    "    batches = round(640 / BATCH_SIZE)\n",
    "        \n",
    "\n",
    "    dataloaderTrain = DataLoader(dataset=datasetTrain, batch_size=BATCH_SIZE , shuffle=True, num_workers=8 )\n",
    "    dataloaderTest = DataLoader(dataset=datasetTest, batch_size=BATCH_SIZE , num_workers=8 )\n",
    "    dataloaderVal = DataLoader(dataset=datasetVal, batch_size=BATCH_SIZE, num_workers=8 )\n",
    "\n",
    "    newModel = PLModel(model.name, model.model, datasetTrain, datasetVal,batch_size = BATCH_SIZE,\n",
    "                           loss = loss, lr = lr, optimName = optimName)\n",
    "    \n",
    "        \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='balValAcc',\n",
    "        dirpath='skin/supervised/'+newModel.writer+'/',\n",
    "        filename= '380pixel'+'-{epoch:02d}-{balValAcc:.2f}',\n",
    "        save_top_k=3,\n",
    "        mode='max',\n",
    "    )\n",
    "    tb_logger = pl_loggers.TensorBoardLogger('logs/', name =newModel.writer)\n",
    "\n",
    "    trainer = pl.Trainer(gpus=gpus, accelerator='dp', max_epochs=num_epochs,\n",
    "                            accumulate_grad_batches = batches,\n",
    "                             logger=tb_logger, callbacks=[lr_monitor, checkpoint_callback]\n",
    "                            )\n",
    "    trainer.fit(newModel)\n",
    "    newModel.recoverBestModel()\n",
    "    newModel.eval()\n",
    "    verifyAccuracy(newModel, dataloaderVal, test=False)\n",
    "    verifyAccuracy(newModel, dataloaderTest)                                    \n",
    "    classificationModel.append(newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T17:51:27.145345Z",
     "start_time": "2021-07-26T17:51:27.141176Z"
    }
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "for model in classificationModel:\n",
    "    if model.name.find('EfficientNet') > -1:\n",
    "        print(model.model._avg_pooling)\n",
    "        model.model._avg_pooling.register_forward_hook(get_activation('avgpool'))\n",
    "    else:\n",
    "        print(model.model.avgpool)\n",
    "        model.model.avgpool.register_forward_hook(get_activation('avgpool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T18:20:40.917980Z",
     "start_time": "2021-07-26T17:51:27.146433Z"
    }
   },
   "outputs": [],
   "source": [
    "#TSNE\n",
    "for model, resolution in zip(classificationModel, resolutions):\n",
    "    torch.save(model.state_dict(), \"LastEfficientNetFamily\" + model.name + \".cpkt\")\n",
    "    datasetTest = TotalDataset(dfTest, imgSize = resolution)\n",
    "    dataloaderTest = DataLoader(dataset=datasetTest, batch_size=BATCH_SIZE , num_workers=8 )\n",
    "    testAccuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
