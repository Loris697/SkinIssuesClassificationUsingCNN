{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../code')\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import randint\n",
    "from skimage.transform import resize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import balanced_accuracy_score, top_k_accuracy_score\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.utils import shuffle\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-rubber",
   "metadata": {
    "code_folding": [
     2,
     17
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_integrated_gradient(batch_x, batch_blank, model, idx):\n",
    "    mean_grad = 0\n",
    "    n = 100\n",
    "\n",
    "    for i in tqdm(range(1, n + 1)):\n",
    "        x = batch_blank + i / n * (batch_x - batch_blank)\n",
    "        x.requires_grad = True\n",
    "        y = model(x)[0, idx]\n",
    "        (grad,) = torch.autograd.grad(y, x)\n",
    "        mean_grad += grad / n\n",
    "\n",
    "    integrated_gradients = (batch_x - batch_blank) * mean_grad\n",
    "\n",
    "    return integrated_gradients\n",
    "\n",
    "def limToOne(image):\n",
    "    for c in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            for y in range(image.shape[2]):\n",
    "                if image[c][x][y] > 1:\n",
    "                    image[c][x][y] = 1.\n",
    "                elif image[c][x][y] < 0:\n",
    "                    image[c][x][y] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "trainSize = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-president",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def verifyAccuracy(model, dataloader, test = True, printcm = False, name = None, save = True):\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        predictions = []\n",
    "        truth = []\n",
    "        \n",
    "        if name is None:\n",
    "            name = model.name\n",
    "        \n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(8)]\n",
    "        n_class_samples = [0 for i in range(8)]\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(images.shape[0]):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                predictions.append(np.array(pred.to('cpu')))\n",
    "                truth.append(np.array(label.to('cpu')))\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network {name}: {acc} %')\n",
    "\n",
    "        truth = np.array(truth)\n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        balAcc = balanced_accuracy_score(truth, predictions)\n",
    "        print(f'Balanced accuracy of the network {name}: {balAcc} %')\n",
    "            \n",
    "        if save:    \n",
    "            if test:\n",
    "                model.testAcc = balAcc\n",
    "            elif model.maxValAcc < balAcc:\n",
    "                model.maxValAcc = balAcc\n",
    "        \n",
    "        if printcm:\n",
    "            cm = confusion_matrix(truth,predictions)\n",
    "            print_confusion_matrix(cm,labelName[:8],name = name)\n",
    "            \n",
    "        print(classification_report(truth, predictions, target_names=labelName[:8]))\n",
    "\n",
    "        for i in range(8):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {labelName[i]}: {acc} %')\n",
    "            \n",
    "        return balAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "skinDataset = []\n",
    "labelName = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]\n",
    "\n",
    "i = 0\n",
    "#Reading the labels\n",
    "df = pandas.read_csv(\"../label.csv\")\n",
    "df = shuffle(df, random_state = 1234)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "dfTrain = df[df[\"MEL\"]==1.].iloc[:round(trainSize*len(df[df[\"MEL\"]==1.]))]\n",
    "\n",
    "for label in [\"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]:\n",
    "    dfTrain = pandas.concat([dfTrain, df[df[label]==1.].iloc[:round(trainSize*len(df[df[label]==1.]))]])\n",
    "    \n",
    "dfTrain = dfTrain.reset_index(drop=True)\n",
    "\n",
    "dfTest = pandas.concat([df,dfTrain]).drop_duplicates(keep=False)\n",
    "dfVal = dfTrain.copy()\n",
    "dfTrain = dfVal[dfVal[\"MEL\"]==1.].iloc[:round(trainSize*len(dfVal[dfVal[\"MEL\"]==1.]))]\n",
    "\n",
    "for label in [\"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\", \"UNK\"]:\n",
    "    dfTrain = pandas.concat([dfTrain, dfVal[dfVal[label]==1.].iloc[:round(trainSize*len(dfVal[dfVal[label]==1.]))]])\n",
    "    \n",
    "\n",
    "dfVal = pandas.concat([dfVal,dfTrain]).drop_duplicates(keep=False)\n",
    "dfTest = dfTest.reset_index(drop=True)\n",
    "dfVal = dfVal.reset_index(drop=True)\n",
    "dfTrain = dfTrain.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per verificare che il dataset sia ben bilanciato\n",
    "def isBalanced(df):\n",
    "    MELCount = len(df[df['MEL']==1.])\n",
    "    NVCount = len(df[df['NV']==1.])\n",
    "    BCCCount = len(df[df['BCC']==1.])\n",
    "    AKCount = len(df[df['AK']==1.])\n",
    "    BKLCount = len(df[df['BKL']==1.])\n",
    "    DFCount = len(df[df['DF']==1.])\n",
    "    VASCCount = len(df[df['VASC']==1.])\n",
    "    SCCCount = len(df[df['SCC']==1.])\n",
    "    UNKCount = len(df[df['UNK']==1.])\n",
    "\n",
    "    print(\"Casi di MEL: \" + str(MELCount))\n",
    "    print(\"Casi di NV: \" + str(NVCount))\n",
    "    print(\"Casi di BCC: \" + str(BCCCount))\n",
    "    print(\"Casi di BKL: \" + str(BKLCount))\n",
    "    print(\"Casi di DF: \" + str(DFCount))\n",
    "    print(\"Casi di VASC: \" + str(VASCCount))\n",
    "    print(\"Casi di SCC: \" + str(SCCCount))\n",
    "    print(\"Casi di UNK: \" + str(UNKCount))\n",
    "\n",
    "print(\"Le dimensioni del dataset di training sono : \"+str(dfTrain.shape[0])+\" , mentre le dimensioni del dataset di test sono \"+str(dfTest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalanceVector(df):\n",
    "    values = []\n",
    "    \n",
    "    for name in labelName[:-1]:\n",
    "        values.append(len(df[df[name]==1.]))\n",
    "        \n",
    "    values = np.array(values)\n",
    "    \n",
    "    return values.sum() / values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "isBalanced(dfTrain)\n",
    "w = BalanceVector(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image, isTensor = False):\n",
    "    if isTensor:\n",
    "        plt.imshow(image.permute(1, 2, 0), interpolation='nearest', aspect='equal')\n",
    "    else:\n",
    "        plt.imshow(image, interpolation='nearest', aspect='equal')\n",
    "    plt.show()\n",
    "    \n",
    "def showLabel(label, prediction = False):\n",
    "    if prediction:\n",
    "        print(\"(Output della rete) La malattia è: \" + labelName[label])\n",
    "    else:\n",
    "        print(\"La malattia è: \" + labelName[label])\n",
    "    \n",
    "def showExample(example, isTensor = False):\n",
    "    showLabel(example[1])\n",
    "    showImage(example[0], isTensor)\n",
    "    \n",
    "def showLatent(label):\n",
    "    print(label.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalDataset(Dataset):\n",
    "    def __init__(self, label,image_size = 224,  aug = False):\n",
    "        self.label = label\n",
    "        self.lenght = self.label.shape[0]\n",
    "        self.imageTransform = transforms.Compose([\n",
    "             transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        self.aug = aug\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        pathImage = '../../ISIC_2019_Training_Input/' + self.label['image'][index] + '.jpg'\n",
    "        label = np.argmax(np.array(self.label.loc[index][1:], dtype = 'float32' )[:-1])\n",
    "        image = self.imageTransform(Image.open(pathImage))\n",
    "        if self.aug:\n",
    "            image = randomTransform(image)\n",
    "        return (image, torch.tensor(label))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(pathImage, image_size = 224):\n",
    "    imageTransform = transforms.Compose([\n",
    "             transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    image = imageTransform(Image.open(pathImage))\n",
    "    return image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PLModel import PLModel\n",
    "from util import print_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-tuesday",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def testAccuracy(model):\n",
    "    PCAVector = []\n",
    "    truth = []\n",
    "    correct = []\n",
    "    correctPred = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for i in range(len(datasetTest)):\n",
    "        output = model(datasetTest[i][0].unsqueeze(0).to(device))\n",
    "        output = np.array(output.detach().to('cpu'))\n",
    "        if datasetTest[i][1] == np.argmax(output[0]):\n",
    "            correctPred += 1\n",
    "            correct.append(i)\n",
    "        PCAVector.append(np.array(activation['avgpool'].to('cpu')).reshape(-1))\n",
    "        truth.append(datasetTest[i][1])\n",
    "        print(\"{:.2f} % ({:d} su {:d}) acc = {:.2f}\".format(100*i/len(datasetTest), i, len(datasetTest), 100 * correctPred / (i + 1)), end=\"\\r\")\n",
    "    print(\"Accuracy of prediction (\"+ model.name+ \") \"+str(correctPred/len(datasetTest)))\n",
    "    \n",
    "    tsne = TSNE(n_components=2)\n",
    "    PCAtoplot = tsne.fit_transform(np.array(PCAVector))\n",
    "    PCAtoplot = np.append(PCAtoplot, np.array(truth).reshape(-1, 1), axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    firstLabel = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    \n",
    "    for x, y, color in PCAtoplot:\n",
    "        color = int(color)\n",
    "        if color == 0:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'bo', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'bo')\n",
    "        if color == 1:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'go', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'go')\n",
    "        if color == 2:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'ro', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'ro')\n",
    "        if color == 3:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'yo', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'yo')\n",
    "        if color == 4:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'kd', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'kd')\n",
    "        if color == 5:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'ch', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'ch')\n",
    "        if color == 6:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'm*', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'm*')\n",
    "        if color == 7:\n",
    "            if firstLabel[color] == 1:\n",
    "                plt.plot(x, y, 'bs', label=labelName[color])\n",
    "                firstLabel[color] = 0\n",
    "            else:\n",
    "                plt.plot(x, y, 'bs')\n",
    "            \n",
    "    plt.ylabel('PC1')\n",
    "    plt.xlabel('PC2')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimName = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(weight = torch.tensor(w).type(torch.FloatTensor) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "Models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6eba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnext50_32x4d', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnext50', resnext, loss = loss, optimName = optimName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnet152', resnext, loss = loss, optimName = optimName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNet', EfficientNet.from_pretrained('efficientnet-b4', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB5', EfficientNet.from_pretrained('efficientnet-b5', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB6', EfficientNet.from_pretrained('efficientnet-b6', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLModel('EfficientNetB7', EfficientNet.from_pretrained('efficientnet-b7', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-crown",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "for model in Models:\n",
    "    if model.name.find(\"EfficientNet\") > -1:\n",
    "        print(model.model._avg_pooling)\n",
    "        model.model._avg_pooling.register_forward_hook(get_activation('avgpool'))\n",
    "    elif model.name.find(\"Densenet\") > -1:\n",
    "        print(model.model.features.norm5)\n",
    "        model.model.features.norm5.register_forward_hook(get_activation('avgpool'))\n",
    "    else:\n",
    "        print(model.model.avgpool)\n",
    "        model.model.avgpool.register_forward_hook(get_activation('avgpool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-window",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cartella = '/home/cino/Documents/BestModel/'\n",
    "bestModel = []\n",
    "\n",
    "for model in Models:\n",
    "    if model.name == 'EfficientNetB7':\n",
    "        subcartella = 'EffNetB7'\n",
    "        image_size = 600\n",
    "    if model.name == 'EfficientNetB6':\n",
    "        subcartella = 'EffNetB6'\n",
    "        image_size = 528\n",
    "    if model.name == 'EfficientNetB5':\n",
    "        subcartella = 'EffNetB5'\n",
    "        image_size = 456\n",
    "    if model.name == 'EfficientNet':\n",
    "        subcartella = 'EffNetB4'\n",
    "        image_size = 380\n",
    "    if model.name == 'Resnext50':\n",
    "        subcartella = 'ResNext50/600px'\n",
    "        image_size = 600\n",
    "    if model.name == 'Resnet152':\n",
    "        subcartella = 'ResNet152/600px'\n",
    "        image_size = 600\n",
    "    mypath = cartella + subcartella\n",
    "    \n",
    "    datasetTest = TotalDataset(dfTest, image_size)\n",
    "    datasetVal = TotalDataset(dfVal, image_size)\n",
    "\n",
    "    dataloaderTest = DataLoader(dataset=datasetTest, batch_size=BATCH_SIZE , num_workers=2 )\n",
    "    dataloaderVal = DataLoader(dataset=datasetVal, batch_size=BATCH_SIZE , num_workers=2 )\n",
    "    \n",
    "    weights = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    \n",
    "    bestAcc = 0\n",
    "    bestValAcc = 0\n",
    "    bestTestAcc = 0\n",
    "    bestM = model\n",
    "    \n",
    "    for weight in weights:\n",
    "        try:\n",
    "            temp = torch.load(mypath + '/' + weight)['state_dict']\n",
    "            del temp['loss.weight']\n",
    "            model.load_state_dict(temp)\n",
    "            print(\"Versione precedente trovata\")\n",
    "        except Exception as e:\n",
    "            print('Caricamento pytorch lig fallito, provo senza cancellare loss.weight' + str(e))\n",
    "            try:\n",
    "                temp = torch.load(mypath + '/' + weight)['state_dict']\n",
    "                model.load_state_dict(temp)\n",
    "                print(\"Versione precedente trovata\")\n",
    "            except Exception as e:\n",
    "                print('Caricamento pytorch lig fallito, provo pytorch' + str(e))\n",
    "                try:\n",
    "                    temp = torch.load(mypath + '/' + weight)\n",
    "                    model.model.load_state_dict(temp)\n",
    "                    print(\"Versione precedente trovata\")\n",
    "                except Exception as e:\n",
    "                    print(\"Impossibile recuperare \" + weight)\n",
    "                    continue\n",
    "        model.eval()\n",
    "        \n",
    "        valAcc = verifyAccuracy(model, dataloaderVal, test = False)\n",
    "        testAcc = verifyAccuracy(model, dataloaderTest, test = True)\n",
    "        acc = valAcc + testAcc\n",
    "        if acc > bestAcc:\n",
    "            bestValAcc = valAcc\n",
    "            bestTestAcc = testAcc\n",
    "            bestM = model\n",
    "            \n",
    "    \n",
    "    correct = testAccuracy(bestM)\n",
    "    tta_model = tta.ClassificationTTAWrapper(bestM, tta.aliases.d4_transform(), merge_mode='mean')\n",
    "    \n",
    "    valAccTTA = verifyAccuracy(tta_model, dataloaderVal, test = False, name = model.name, save = False)\n",
    "    testAccTTA = verifyAccuracy(tta_model, dataloaderTest, test = True, name = model.name, save = False)\n",
    "    \n",
    "    print(model.name, bestValAcc, bestTestAcc, valAccTTA, testAccTTA)\n",
    "    bestModel.append((bestM, model.name, bestValAcc, bestTestAcc, valAccTTA, testAccTTA, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-telescope",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    example = randint(0, len(datasetTest)-1)\n",
    "    for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "        image = datasetTest[example][0]\n",
    "        batch_x = image.unsqueeze(0)\n",
    "        model.to('cpu')\n",
    "        pred = torch.argmax(model(batch_x))\n",
    "        print('Il modello '+model.name+' ha predetto '+labelName[pred]+'('+labelName[datasetTest[example][1]]+')')\n",
    "\n",
    "        if model.name.find('EfficientNet') > -1:\n",
    "            target_layer = model.model._blocks[-1]\n",
    "        else:\n",
    "            target_layer = model.model.layer4[-1]\n",
    "        # Construct the CAM object once, and then re-use it on many images:\n",
    "        cam = GradCAMPlusPlus(model=model, target_layer=target_layer)\n",
    "\n",
    "        # If target_category is None, the highest scoring category\n",
    "        # will be used for every image in the batch.\n",
    "        # target_category can also be an integer, or a list of different integers\n",
    "        # for every image in the batch.\n",
    "        target_category = datasetTest[example][1]\n",
    "        target_category = target_category.unsqueeze(0)\n",
    "\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=batch_x, target_category=target_category, aug_smooth=True)\n",
    "\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        visualization = show_cam_on_image(np.array(image.permute(1, 2, 0)), grayscale_cam, use_rgb=True)\n",
    "        f, axarr = plt.subplots(1,2, figsize=(12, 12))\n",
    "        axarr[0].imshow(image.permute(1, 2, 0), interpolation='nearest', aspect='equal')\n",
    "        axarr[1].imshow(visualization, interpolation='nearest', aspect='equal')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-rapid",
   "metadata": {},
   "source": [
    "for i in range(3):\n",
    "    example = randint(0, len(datasetTest)-1)\n",
    "    for model in Models:\n",
    "        image = datasetTest[example][0]\n",
    "        batch_blank = torch.zeros(1, 3, 224, 224).to(device)\n",
    "        batch_x = image.unsqueeze(0).to(device)\n",
    "        model.to(device)\n",
    "        pred = torch.argmax(model(batch_x))\n",
    "        print('Il modello '+model.name+' ha predetto '+labelName[pred]+'('+labelName[datasetTest[example][1]]+')')\n",
    "        integrated_gradients = compute_integrated_gradient(batch_x, batch_blank, model, 0)[0, :, :, :].to('cpu')\n",
    "        f, axarr = plt.subplots(1,2, figsize=(12, 12))\n",
    "        axarr[0].imshow(image.permute(1, 2, 0), interpolation='nearest', aspect='equal')\n",
    "        axarr[1].imshow(limToOne(integrated_gradients.permute(1, 2, 0)), interpolation='nearest', aspect='equal')\n",
    "        plt.show()\n",
    "        showImage(limToOne(image + integrated_gradients), isTensor = True)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    y.append(val*100)\n",
    "    x.append(name)\n",
    "    \n",
    "x[-1] = x[-1] + \"B4\"\n",
    "    \n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Data\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Histogram\");\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "#for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "#    y.append(test*100)\n",
    "#    x.append(name)\n",
    "    \n",
    "#x[-1] = x[-1] + \"B4\"\n",
    "\n",
    "x = ['Resnext50', 'Resnet152', 'EfficientNetB7', 'EfficientNetB6', 'EfficientNetB5', 'EfficientNetB4']\n",
    "y = [87.06392931234282, 86.56985572727665, 86.0222951692196, 84.99923862320729, 85.3735109502255, 84.65377269774773]\n",
    "    \n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Test\", color=\"green\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Histogram\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    y.append(valTTA*100)\n",
    "    x.append(name)\n",
    "    \n",
    "\n",
    "x[-1] = x[-1] + \"B4\"\n",
    "\n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Validation TTA\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Histogram\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    y.append(testTTA*100)\n",
    "    x.append(name)\n",
    "    \n",
    "x[-1] = x[-1] + \"B4\"\n",
    "    \n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Ttest TTA\", color = \"green\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy gain')\n",
    "plt.title(\"Histogram of TTA gains\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    y.append((valTTA - val)*100)\n",
    "    x.append(name)\n",
    "    \n",
    "x[-1] = x[-1] + \"B4\"\n",
    "    \n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Validation TTA difference\", color = \"red\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy gain')\n",
    "plt.title(\"Histogram of TTA gains\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1, figsize = (11,11))\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    y.append((testTTA - test)*100)\n",
    "    x.append(name)\n",
    "    \n",
    "x[-1] = x[-1] + \"B4\"\n",
    "    \n",
    "plt.hist(x, weights = y, density=False, bins=len(x)*2, label=\"Test TTA difference\", color = \"red\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Accuracy gain')\n",
    "plt.title(\"Histogram of TTA gains Test\" )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongTot = range(len(datasetTest))\n",
    "minError = len(datasetTest)\n",
    "class_wrong = [0 for i in range(8)]\n",
    "\n",
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    if minError > len(correct):\n",
    "        minError = len(correct)\n",
    "        \n",
    "    wrongTot = [i for i in wrongTot if i not in correct]\n",
    "    \n",
    "for i in wrongTot:\n",
    "    class_wrong[datasetTest[i][1]] = class_wrong[datasetTest[i][1]] + 1\n",
    "\n",
    "print(\"Il \"+str(100*len(wrongTot)/minError)+\" è sbagliato da tutte le reti\")\n",
    "print(class_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "    print( name, val, test, valTTA, testTTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    example = randint(0, len(wrongTot)-1)\n",
    "    print(example)\n",
    "    for model, name, val, test, valTTA, testTTA, correct in bestModel:\n",
    "        image = datasetTest[wrongTot[example]][0]\n",
    "        batch_x = image.unsqueeze(0)\n",
    "        model.to('cpu')\n",
    "        pred = torch.argmax(model(batch_x))\n",
    "        print('Il modello '+model.name+' ha predetto '+labelName[pred]+'('+labelName[datasetTest[wrongTot[example]][1]]+')')\n",
    "\n",
    "        if model.name.find('EfficientNet') > -1:\n",
    "            target_layer = model.model._blocks[-1]\n",
    "        else:\n",
    "            target_layer = model.model.layer4[-1]\n",
    "        # Construct the CAM object once, and then re-use it on many images:\n",
    "        cam = GradCAMPlusPlus(model=model, target_layer=target_layer)\n",
    "\n",
    "        # If target_category is None, the highest scoring category\n",
    "        # will be used for every image in the batch.\n",
    "        # target_category can also be an integer, or a list of different integers\n",
    "        # for every image in the batch.\n",
    "        target_category = datasetTest[wrongTot[example]][1]\n",
    "        target_category = target_category.unsqueeze(0)\n",
    "\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=batch_x, target_category=target_category, aug_smooth=True)\n",
    "\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        visualization = show_cam_on_image(np.array(image.permute(1, 2, 0)), grayscale_cam, use_rgb=True)\n",
    "        f, axarr = plt.subplots(1,2, figsize=(12, 12))\n",
    "        axarr[0].imshow(image.permute(1, 2, 0), interpolation='nearest', aspect='equal')\n",
    "        axarr[1].imshow(visualization, interpolation='nearest', aspect='equal')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wrongTot)):\n",
    "    showExample(datasetTest[i], isTensor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-discovery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
